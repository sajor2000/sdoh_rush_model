
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Understanding SHAP Analysis - Executive Guide</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            line-height: 1.6;
            color: #333;
            max-width: 1000px;
            margin: 0 auto;
            padding: 20px;
            background-color: #f4f4f4;
        }
        .container {
            background-color: white;
            padding: 30px;
            border-radius: 10px;
            box-shadow: 0 0 20px rgba(0,0,0,0.1);
        }
        h1 {
            color: #2c3e50;
            border-bottom: 3px solid #e74c3c;
            padding-bottom: 10px;
        }
        h2 {
            color: #34495e;
            margin-top: 30px;
        }
        .plot-explanation {
            background-color: #ecf0f1;
            padding: 20px;
            border-radius: 8px;
            margin: 20px 0;
            border-left: 5px solid #e74c3c;
        }
        .example-box {
            background-color: #e8f6f3;
            padding: 15px;
            border-radius: 5px;
            margin: 15px 0;
        }
        .key-point {
            background-color: #fef9e7;
            padding: 10px;
            border-left: 4px solid #f39c12;
            margin: 10px 0;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>Understanding SHAP (SHapley Additive exPlanations) Analysis</h1>
        <p style="font-size: 1.1em; color: #666;">A Guide for Healthcare Professionals</p>
        
        <h2>What is SHAP? (In Simple Terms)</h2>
        <p><strong>SHAP helps us understand "why" the AI model made a specific prediction for each patient.</strong></p>
        
        <p>Think of it like this: When a doctor makes a diagnosis, they can explain their reasoning: "This patient has diabetes risk because of their age, family history, and weight." SHAP does the same thing for AI models - it shows which factors pushed the risk score up or down for each individual patient.</p>
        
        <div class="key-point">
            <strong>Key Benefit:</strong> SHAP turns "black box" AI into transparent, explainable decisions that clinicians can understand and trust.
        </div>
        
        <div class="key-point">
            <strong>Key Insight:</strong> SHAP values tell us not just what features are important, but HOW they influence each specific prediction.
        </div>
        
        <h2>Understanding Different SHAP Plots</h2>
        
        <div class="plot-explanation">
            <h3>1. SHAP Summary Plot (Bee Swarm Plot)</h3>
            <p><strong>What it shows:</strong> Overall feature importance and impact distribution across all patients</p>
            <p><strong>How to read it:</strong></p>
            <ul>
                <li>Features are ranked by importance (top to bottom)</li>
                <li>Each dot represents one patient</li>
                <li>Color shows feature value (red = high, blue = low)</li>
                <li>Position on x-axis shows impact on prediction</li>
            </ul>
            <div class="example-box">
                <strong>Clinical Example:</strong> If "Area Deprivation Index" shows red dots on the right, it means patients living in more deprived neighborhoods have higher SDOH risk. This makes clinical sense - areas with limited resources often have residents with more unmet social needs.
            </div>
        </div>
        
        <div class="plot-explanation">
            <h3>2. SHAP Waterfall Plot</h3>
            <p><strong>What it shows:</strong> How we arrived at a prediction for ONE specific patient</p>
            <p><strong>How to read it:</strong></p>
            <ul>
                <li>Starts from baseline prediction (average for all patients)</li>
                <li>Each bar shows how a feature pushes prediction up (red) or down (blue)</li>
                <li>Final value is the patient's risk score</li>
            </ul>
            <div class="example-box">
                <strong>Clinical Example:</strong> 
                <br><strong>72-year-old patient:</strong>
                <br>• Baseline risk: 6.6% (average for all patients)
                <br>• Lives in high-deprivation area: +4.2% (increases risk)
                <br>• Has Medicaid insurance: +2.1% (increases risk)  
                <br>• Age 72 (vs average): +1.5% (increases risk)
                <br>• Female gender: -0.8% (decreases risk)
                <br><strong>Final predicted risk: 13.6%</strong>
                <br><em>→ Recommend SDOH screening (above 8.4% threshold)</em>
            </div>
        </div>
        
        <div class="plot-explanation">
            <h3>3. SHAP Dependence Plot</h3>
            <p><strong>What it shows:</strong> Relationship between a feature's value and its impact</p>
            <p><strong>How to read it:</strong></p>
            <ul>
                <li>X-axis: Feature value (e.g., age from 18-90)</li>
                <li>Y-axis: SHAP value (impact on prediction)</li>
                <li>Color: Often shows interaction with another feature</li>
            </ul>
            <div class="example-box">
                <strong>Example:</strong> Shows that SDOH risk decreases with age, but the relationship is stronger in urban areas (shown by color).
            </div>
        </div>
        
        <div class="plot-explanation">
            <h3>4. SHAP Force Plot</h3>
            <p><strong>What it shows:</strong> Visual explanation of a single prediction</p>
            <p><strong>How to read it:</strong></p>
            <ul>
                <li>Base value (left) to final prediction (right)</li>
                <li>Red features push prediction higher</li>
                <li>Blue features push prediction lower</li>
                <li>Width shows magnitude of impact</li>
            </ul>
        </div>
        
        <h2>Why SHAP Matters for Healthcare</h2>
        
        <div class="key-point">
            <h3>1. Transparency & Trust</h3>
            <p>Clinicians can see exactly why a patient was flagged as high-risk, building confidence in AI recommendations.</p>
        </div>
        
        <div class="key-point">
            <h3>2. Actionable Insights</h3>
            <p>Identifies specific factors driving risk for each patient, enabling targeted interventions.</p>
        </div>
        
        <div class="key-point">
            <h3>3. Bias Detection</h3>
            <p>Reveals if the model relies too heavily on demographic factors vs. modifiable risk factors.</p>
        </div>
        
        <div class="key-point">
            <h3>4. Quality Improvement</h3>
            <p>Helps identify which community-level factors most impact patient outcomes, guiding population health strategies.</p>
        </div>
        
        <h2>Practical Applications</h2>
        
        <h3>For Individual Patients:</h3>
        <ul>
            <li>Explain to patients why they were selected for screening</li>
            <li>Identify modifiable risk factors for intervention</li>
            <li>Guide care planning based on specific drivers</li>
        </ul>
        
        <h3>For Population Health:</h3>
        <ul>
            <li>Identify neighborhoods needing resources</li>
            <li>Target community partnerships</li>
            <li>Allocate preventive services efficiently</li>
        </ul>
        
        <h3>For Quality Assurance:</h3>
        <ul>
            <li>Verify model uses appropriate factors</li>
            <li>Ensure fairness across demographics</li>
            <li>Monitor for unexpected patterns</li>
        </ul>
        
        <div style="background-color: #d5e8d4; padding: 20px; border-radius: 8px; margin-top: 30px;">
            <h3 style="margin-top: 0;">✅ Key Takeaway</h3>
            <p>SHAP analysis transforms the AI "black box" into a transparent tool that provides clear, actionable explanations for each prediction. This enables clinicians to trust the model, understand individual patient risks, and make informed intervention decisions.</p>
        </div>
    </div>
</body>
</html>
